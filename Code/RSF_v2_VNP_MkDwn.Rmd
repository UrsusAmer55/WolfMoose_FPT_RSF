# Habitat selection models in R

Load libraries

```{r warning=FALSE, message=FALSE}
library(chron)
library(rgdal)  
library(maptools)
library(raster)
library(rgdal)
library(shapefiles)
library(rgeos)
library(adehabitatHR)
library(spatstat)
library(lattice)
library(ResourceSelection) 
library(splancs)  # for csr to generate random points
library(KernSmooth)
library(nlme)
library(sp)
```

First, delete everything in working memory.

```{r }
   #rm(list=ls(all=TRUE))
```


Read in data, clean it up, combine packs and remove those "without home ranges" according to Steve
```{r}
###orig wolf data
wolf<-read.csv("E:/Moose/Data/Voyageurs_National_Park/AllVNPWolf_MD102815.csv",header=TRUE)
#table(as.factor(wolf$WOLFID),wolf$WOLFID)

###2015 Lotek Data
lowolf<-read.csv("E:/Moose/Data/Voyageurs_National_Park/VNPwolfdataMark112515/VNPwolfdataMark112515/Lotek111715.csv",header=TRUE)
###remove misses
lowolfC<-lowolf[lowolf$Latitude!=0,]
#table(as.factor(lowolfC$WOLFID),lowolfC$WOLFID)

###2015 Lotek Data
vecwolf<-read.csv("E:/Moose/Data/Voyageurs_National_Park/VNPwolfdataMark112515/VNPwolfdataMark112515/Vect111715.csv",header=TRUE)
###remove misses
vecwolfC<-vecwolf[vecwolf$Latitude!=0,]
#table(as.factor(vecwolfC$WOLFID),vecwolfC$WOLFID)

###subset orig data to just the ones not included in 2015 updated data
### set up all the attributes so they can all be combined with the same names
wolfO<-wolf
wolfOrigC<-wolfO[wolfO$WOLFID=="V003"|wolfO$WOLFID=="V007"|wolfO$WOLFID=="V008"|wolfO$WOLFID=="V010"|wolfO$WOLFID=="V011"|wolfO$WOLFID=="V012",]
unique(wolfOrigC$WOLFID)
head(wolfOrigC)
wolfvar<-c("OBJECTID","WOLFID","Latitude","Longitude","Altitude","Date","Time","Temp_C")
wolfOrigC<-wolfOrigC[(wolfvar)]
head(wolfOrigC)
wolfOrigC$Time <- chron(times=as.character(wolfOrigC$Time))
wolfOrigC$Date<- as.POSIXlt(wolfOrigC$Date, format= "%m/%d/%Y")
wolfOrigC$dtm <- as.factor(paste(wolfOrigC$Date, wolfOrigC$Time, sep = " "))
wolfOrigC$dtPm<-strptime(wolfOrigC$dtm, "%Y-%m-%d %H:%M:%S")
str(wolfOrigC$dtPm)
wolfOrigC$dtPm <- as.POSIXct(wolfOrigC$dtPm)



###keep all LOtek - change blanks to "V047, and set up attribute names
lowolfC$WOLFID<-as.character(lowolfC$WOLFID)
lowolfC$WOLFID[lowolfC$WOLFID==""] <- "V047"
lowolfC2<-lowolfC
head(lowolfC2)
###remove locations with a ton of error
lowolfC3<-lowolfC2[c(lowolfC2$DOP<15),]
lovars<-c("OBJECTID","WOLFID","Latitude","Longitude","Altitude","DateTimeGMT","Temp")
lowolfC3<-lowolfC3[(lovars)]
head(lowolfC3)
lowolfC3$DateTimeGMT<- as.POSIXlt(lowolfC3$DateTimeGMT, format= "%m/%d/%Y %H:%M")
lowolfC3$dtPm <- as.POSIXct(lowolfC3$DateTimeGMT, tz="GMT")
lowolfC3$dtPm<-format(lowolfC3$dtPm, tz="America/Chicago",usetz=TRUE)

### Vectronic data - do the same as above - different attribute names
###remove locations with a ton of error
vecwolfC2<-vecwolfC[c(vecwolfC$DOP<15),]
vecvars<-c("OBJECTID","WOLFID","Latitude","Longitude","Height","UTC_Date","UTC_Time","TempC")
vecwolfC3<-vecwolfC2[(vecvars)]
head(vecwolfC3)
#vecwolfC3$UTC_Time <- chron(times=as.character(vecwolfC3$UTC_Time))
vecwolfC3$UTC_Date<- as.POSIXlt(vecwolfC3$UTC_Date, format= "%m/%d/%Y ")
vecwolfC3$dtm <- as.factor(paste(vecwolfC3$UTC_Date, vecwolfC3$UTC_Time, sep = " "))
vecwolfC3$dtPm<-strptime(vecwolfC3$dtm, "%Y-%m-%d %H:%M:%S")
vecwolfC3$dtPm <- as.POSIXct(vecwolfC3$dtPm, tz="GMT")
vecwolfC3$dtPm<-format(vecwolfC3$dtPm, tz="America/Chicago",usetz=TRUE)
head(vecwolfC3)
###change names of attributes for combining into single data set
colnames(wolfOrigC) <- c("OBJECTID","WOLFID","Latitude","Longitude","Altitude","Date","Time","Temp","dtm","dtPm")
colnames(lowolfC3) <- c("OBJECTID","WOLFID","Latitude","Longitude","Altitude","DateTime","Temp","dtPm")
colnames(vecwolfC3) <- c("OBJECTID","WOLFID","Latitude","Longitude","Altitude","Date","Time","Temp","dtm","dtPm")

wolfvarF<-c("OBJECTID","WOLFID","Latitude","Longitude","Altitude","dtPm","Temp")
wolfOrigCF<-wolfOrigC[(wolfvarF)]
lowolfC3F<-lowolfC3[(wolfvarF)]
vecwolfC3F<-vecwolfC3[(wolfvarF)]

###combine to 1 dataset
Wolf1215<-rbind(wolfOrigCF,lowolfC3F,vecwolfC3F)
###order the data
Wolf1215 <- Wolf1215[order(Wolf1215$WOLFID,Wolf1215$dtPm),]
###number of locs by WOLFID
table(Wolf1215$WOLFID)

###create time attributes
Wolf1215$jul<-format(Wolf1215$dtPm,"%j")
Wolf1215$month<-format(Wolf1215$dtPm,format="%m")
Wolf1215$month<-as.numeric(Wolf1215$month)

###duplicate check
Wolf1215$DupCheck<-paste(Wolf1215$WOLFID,Wolf1215$jul,Wolf1215$Latitude,Wolf1215$Longitude,sep="")
which(duplicated(Wolf1215$DupCheck))
dups<-Wolf1215[duplicated(Wolf1215$DupCheck), ]

###add seasonality attribute
Wolf1215$season<-NA
Wolf1215$season[Wolf1215$month>=4 & Wolf1215$month<7]<- "Spring"
Wolf1215$season[Wolf1215$month>=7 & Wolf1215$month<=11]<- "Summer"
Wolf1215$season[Wolf1215$month==11 | Wolf1215$month==12 | Wolf1215$month==01 | Wolf1215$month==02 | Wolf1215$month==03 ]<- "Winter"


###calculate the diff (in seconds) between fixes
Wolf1215$time.diff<-c(0,as.numeric(diff(Wolf1215$dtPm)))
### remove the negative times (result from end of 1 data set to the next - we wanted to remove 1 day or so of data anyways after capture)
Wolf1215c<-subset(Wolf1215,Wolf1215$time.diff>0)


### I put the date as 8/5/2013 for V014 for all locs since didnt know it - this will be summer
Wolf1215c_4hr<-Wolf1215c
#combine ID to new group/pack ID
Wolf1215c_4hr$PACKID<-NA
### 007 and 030 need to be combined
Wolf1215c_4hr$PACKID[Wolf1215c_4hr$WOLFID=="V030" | Wolf1215c_4hr$WOLFID=="V007"]<- "V0730"
###remove Wolf 28
Wolf1215c_4hr<-Wolf1215c_4hr[c(Wolf1215c_4hr$WOLFID!="V028"),] 
### combine 24 and 14
Wolf1215c_4hr$PACKID[Wolf1215c_4hr$WOLFID=="V024" | Wolf1215c_4hr$WOLFID=="V014"]<- "V1424"
### V011 7/7/13 to 11/12/13 and (separate territory) 1/30/14 to end of dataset 
Wolf1215c_4hr$PACKID[Wolf1215c_4hr$WOLFID=="V011"&Wolf1215c_4hr$dtPm<="2013-11-12" ] <- "V1101"
Wolf1215c_4hr$PACKID[Wolf1215c_4hr$WOLFID=="V011"&Wolf1215c_4hr$dtPm>"2013-11-12" ] <- "V1102"
### V029 7/22/14 to 11/14/14 and (separate territory) 12/16/14 to end of dataset 
Wolf1215c_4hr$PACKID[Wolf1215c_4hr$WOLFID=="V029"&Wolf1215c_4hr$dtPm<="2014-11-14" ] <- "V2901"
Wolf1215c_4hr$PACKID[Wolf1215c_4hr$WOLFID=="V029"&Wolf1215c_4hr$dtPm>"2014-11-14" ] <- "V2902"
### group V003 prior to 10/9/2012 with V029 main (first) territory
Wolf1215c_4hr$PACKID[Wolf1215c_4hr$WOLFID=="V003"&Wolf1215c_4hr$dtPm<="2012-10-09" ] <- "V2901"
Wolf1215c_4hr$PACKID[Wolf1215c_4hr$WOLFID=="V003"&Wolf1215c_4hr$dtPm>"2012-10-09" ] <- "V003"
### exclude V003 after 10/9/2012 - dispersal

Wolf1215c_4hr$PACKID<-as.character(Wolf1215c_4hr$PACKID)
Wolf1215c_4hr$WOLFID<-as.character(Wolf1215c_4hr$WOLFID)

Wolf1215c_4hr$PACKID <- ifelse(is.na(Wolf1215c_4hr$PACKID), Wolf1215c_4hr$WOLFID, Wolf1215c_4hr$PACKID)

###combine season and packGRoup
Wolf1215c_4hr$packIDseas<-paste(Wolf1215c_4hr$PACKID,Wolf1215c_4hr$season,sep="_")


#remove additional packs for various reasons (dispersal, few fixes etc)
### summer
#V023_Summer,V038_Summer,V035_Summer,V1101_Summer
Wolf1215c_4hr<-subset(Wolf1215c_4hr,Wolf1215c_4hr$packIDseas!="V023_Summer"&Wolf1215c_4hr$packIDseas!="V038_Summer"&Wolf1215c_4hr$packIDseas!="V035_Summer"&Wolf1215c_4hr$packIDseas!="V1101_Summer")

### winter
#V023_Winter,V1424_Winter,V1102_Winter,V2902_Winter
Wolf1215c_4hr<-subset(Wolf1215c_4hr,Wolf1215c_4hr$packIDseas!="V023_Winter"&Wolf1215c_4hr$packIDseas!="V1424_Winter"&Wolf1215c_4hr$packIDseas!="V1102_Winter"&Wolf1215c_4hr$packIDseas!="V2902_Winter")

###spring 
Wolf1215c_4hr<-subset(Wolf1215c_4hr,Wolf1215c_4hr$packIDseas!="V035_Spring"&Wolf1215c_4hr$packIDseas!="V1424_Spring"&Wolf1215c_4hr$packIDseas!="V1102_Spring"&Wolf1215c_4hr$packIDseas!="V2902_Spring")
table(Wolf1215c_4hr$packIDseas)

summary(Wolf1215c_4hr$time.diff)
```

Remove locations further than 12 hours and 90 secs from previous
from 39199-37903 (removes 1,296 fixes)
```{r }
Wolf1215c_4hr2<-Wolf1215c_4hr[Wolf1215c_4hr$time.diff<=43290,]
Wolf1215c_4hr<-Wolf1215c_4hr2

```

Project wolf locs into UTM from lat/long
```{r }
Wolf1215c_4hr$XY<- project(cbind(Wolf1215c_4hr$Longitude, Wolf1215c_4hr$Latitude), "+proj=utm +zone=15 ellps=WGS84")
Wolf1215c_4hr$Y<-Wolf1215c_4hr$XY[,2]
Wolf1215c_4hr$X<-Wolf1215c_4hr$XY[,1]

Wolf1215c_4hr_SP<-SpatialPointsDataFrame(coords=Wolf1215c_4hr[c("X","Y")],proj4string= CRS("+proj=utm +zone=15 ellps=WGS84"),data=Wolf1215c_4hr)
```

Create periods of day at VNP based on time stamp

```{r }
str(Wolf1215c_4hr)
#UTC time - dtPm is local

Wolf1215c_4hr$EndTimeUTC<-format(Wolf1215c_4hr$dtPm, tz="GMT",usetz=TRUE)

VNPloc <- matrix(c(-92.8823,48.5000), nrow=1)
Wolf1215c_4hr$sunpos<-solarpos(VNPloc,Wolf1215c_4hr$dtPm)[,2]

#https://www.timeanddate.com/astronomy/different-types-twilight.html

Wolf1215c_4hr$DayPeriod<-NA
Wolf1215c_4hr$DayPeriod[Wolf1215c_4hr$sunpos<12&Wolf1215c_4hr$sunpos>-12]<-"Crepuscular"
Wolf1215c_4hr$DayPeriod[Wolf1215c_4hr$sunpos>=12]<-"Day"
Wolf1215c_4hr$DayPeriod[Wolf1215c_4hr$sunpos<=-12]<-"Night"

str(Wolf1215c_4hr)

###combine pack-season and now time of day
Wolf1215c_4hr$packIDseasTOD<-paste(Wolf1215c_4hr$packIDseas,Wolf1215c_4hr$DayPeriod,sep="_")
unique(Wolf1215c_4hr$packIDseasTOD)
```

test whether signif differences among movement by time of day by pack-seas

```{r }


nobs<-nrow(Wolf1215c_4hr)  

#distance between locs
Wolf1215c_4hr <- Wolf1215c_4hr[order(Wolf1215c_4hr$WOLFID,Wolf1215c_4hr$dtPm),]
Wolf1215c_4hr$dist<-c(0,sqrt((Wolf1215c_4hr$X[-1]-Wolf1215c_4hr$X[-nobs])^2+(Wolf1215c_4hr$Y[-1]-Wolf1215c_4hr$Y[-nobs])^2))

#recalc time diff
###calculate the diff (in seconds) between fixes
Wolf1215c_4hr$time.diff<-c(0,as.numeric(diff(Wolf1215c_4hr$dtPm)))


#turn into movement rate - meters per second
Wolf1215c_4hr$moverate<-Wolf1215c_4hr$dist/Wolf1215c_4hr$time.diff

###remove super short intervals and way too fast by keeping those with the following reqs
movetest<-Wolf1215c_4hr[Wolf1215c_4hr$moverate<=10&Wolf1215c_4hr$time.diff>=300,]
### remove fixes more than 8 hours apart
#8*(60*60)
movetest2<-movetest[movetest$time.diff<=28920,]

summary(movetest2$time.diff)
summary(movetest2$moverate)
hist(movetest2$moverate)

movetest2$seasTOD<-paste(movetest2$season,movetest2$DayPeriod,sep="_")

mod<-lm(movetest2$moverate~as.factor(movetest2$seasTOD))
summary(mod)
boxplot(movetest2$moverate~as.factor(movetest2$seasTOD))


move1<-lme(moverate~as.factor(seasTOD), data=movetest2, random=~1|WOLFID)
summary(move1)
###results show that for summer and winter move rates highest in crep, then day, then slowest at night
###releveling to look at spring better
movetest2$seasTOD<-as.factor(movetest2$seasTOD)
movetest2$seasTOD <- relevel(movetest2$seasTOD, ref = "Winter_Day")

move2<-lme(moverate~as.factor(seasTOD), data=movetest2, random=~1|WOLFID)
summary(move2)
####this shows that for spring wolves moved about the same speed in crep and night and fastest during day but we have much fewer data for spring - spring has by far the least variability among times of day

# move1<-glmer(moverate~as.factor(seasTOD)+(1 |WOLFID ), data=movetest2, family=gaussian())
#   summary(move1)
# ?glmer

```


Here we select a pack-season-TOD and make them the "used" points
```{r cache=TRUE}

# saveRDS(Wolf1215c_4hr,"E:/Moose/FPT/DataProc/Wolf_RSF_100516.R")
 Wolf1215c_4hr<-readRDS("E:/Moose/FPT/DataProc/Wolf_RSF_100516.R")


table(Wolf1215c_4hr$packIDseasTOD)
use<-Wolf1215c_4hr[Wolf1215c_4hr$packIDseasTOD=="V008_Winter_Night" ,] # sp class

filename<-unique(use$packIDseasTOD)

str(use)

use<-SpatialPoints(use[c("X","Y")])
plot(use)
str(use)

```
Generate some random points from within the `area used by the pack-season
One option is to use an overly smoothed KDE of the UD (e.g., using KDE with h = href) to define availability

```{r cache=TRUE}
# UD estimate from entire season
HR<-Wolf1215c_4hr[Wolf1215c_4hr$packIDseas=="V008_Winter" ,] # sp class
HR<-SpatialPoints(HR[c("X","Y")])
UD.apollo<-kernelUD(HR, h="href")
image(UD.apollo)

# Outer 95% contour
ver <- getverticeshr(UD.apollo, 95)
plot(ver)
points(use) 
```
 
Drop used points that fall outside off the 95% KDE. 
You need as many "point.in.polygon" funcs as their are unique polygons in home range

```{r }
kdecontour1<-ver@polygons[[1]]@Polygons[[1]]@coords
kdecontour2<-ver@polygons[[1]]@Polygons[[2]]@coords
#kdecontourA<-rbind(kdecontour1,kdecontour2)


inkde1<-point.in.polygon(use@coords[,1],use@coords[,2], kdecontour1[,1], kdecontour1[,2])
inkde2<-point.in.polygon(use@coords[,1],use@coords[,2], kdecontour2[,1], kdecontour2[,2])

use<-use[inkde1==1|inkde2==1,]

nuse<-nrow(use@coords)
nuse

```

Generate random points using the csr function in splancs library, but it would be 'best' to generate points on a uniform grid.
```{r }
nav<-1 # number of availble points per used point
navail<-nuse*nav
#  avail<-csr(ver@polygons[[1]]@Polygons[[1]]@coords,navail)
avail<-spsample(ver, n=navail, 'regular')
plot(ver)
points(avail, col="red")
points(use)
```

Read in NLCD (Veg), distance to snowmobile trail, distance to nearest pond/lake 
We need to extract covariate values for all of the available and used  points

```{r }
avail<-avail@coords
avails<-data.frame(LONG_X=avail[,1], LAT_Y=avail[,2]) 

vegR<-raster("E:/Moose/Data/OutsideSpatial/NLCD11VNPclip1.tif") #raster: NLCD habitat
nlcdtab<-read.csv("E:/Moose/Data/OutsideSpatial/NLCD11_Table.csv",header=TRUE) #table so you can see what raster value = #list of hab class
nlcdtab[1:2]
# 
# lake30<-raster("E:/Moose/Data/Voyageurs_National_Park/lakedist30")
# lakepnd30<-raster("E:/Moose/Data/Voyageurs_National_Park/lakepnddist30")
# snowmob<-readOGR("E:/Moose/Data/OutsideSpatial",layer="snowmobile_trails_mn_studyclip") #shapfefiles: snowmobile trails
# #convert snowmob to useable psp
# snowmob.psp = as.psp(snowmob)

####distance to water body, at least .5HA for larger region - use this one!
waterboddist<-raster("E:/Moose/Data/OutsideSpatial/All_MN_Water/distwat_5ha2")

##snowmobile trails
snowmob<-readOGR("E:/Moose/Data/OutsideSpatial/NewSteveSnowmobileVNP",layer="All_DNR_VNPtrails") #shapfefiles: snowmobile trails
snowmob.psp = as.psp(snowmob)


##roads
roads<-readOGR("E:/Moose/Data/OutsideSpatial/Roads/Koochiching",layer="Koochiching_Roads")
roads.psp = as.psp(roads)

##trails
trails<-readOGR("E:/Moose/Data/OutsideSpatial/Trails",layer="state_park_trails_roads_VNPclip")
trails.psp = as.psp(trails)



#extract the data from the spatial layers - avail
avails$veg<-extract(vegR, avails[,1:2])
# avails$lakedist<-extract(lake30, avails[,1:2])
# avails$lakepnddist<-extract(lakepnd30, avails[,1:2])
avails$waterboddist<-extract(waterboddist, avails[,1:2])
avails$waterboddist[is.na(avails$waterboddist)] <- 0


avails$distsnowmob<-nncross(avail, snowmob.psp)$dist 
avails$distroad<-nncross(avail, roads.psp)$dist 
avails$disttrail<-nncross(avails, trails.psp)$dist 
#extract the data from the spatial layers - used
used<-data.frame(use)
used$veg<-extract(vegR, used[,1:2])
# used$lakedist<-extract(lake30, used[,1:2])
# used$lakepnddist<-extract(lakepnd30, used[,1:2])
used$waterboddist<-extract(waterboddist, used[,1:2])
used$waterboddist[is.na(used$waterboddist)] <- 0

used$distroad<-nncross(used, roads.psp)$dist 
used$distsnowmob<-nncross(used, snowmob.psp)$dist 
used$disttrail<-nncross(used, trails.psp)$dist 

# Find the min. distance to linear feature (road,snowmob,trail)
used$distlinear <- ifelse(used$distroad > used$distsnowmob, used$distsnowmob,used$distroad)
used$distlinear2 <- ifelse(used$distlinear > used$disttrail, used$disttrail,used$distlinear)

avails$distlinear <- ifelse(avails$distroad > avails$distsnowmob,avails$distsnowmob,avails$distroad)
avails$distlinear2 <- ifelse(avails$distlinear > avails$disttrail, avails$disttrail,avails$distlinear)

####Combine very similar/seldom used habitat values (Herbaceous and Emergenent...)

# Wolf1215c_4hr<-subset(Wolf1215c_4hr, select=-c(XY))
# 
# used_SP<-SpatialPointsDataFrame(coords=Wolf1215c_4hr[c("X","Y")],proj4string= CRS("+proj=utm +zone=15 ellps=WGS84"),data=Wolf1215c_4hr)
# 
# writeOGR(used_SP,dsn="E:/Moose/Data/Voyageurs_National_Park/WolfTests_092816",layer="Wolf_RSF_100516",driver="ESRI Shapefile")

```
 
Create the response (y = 0 for available, 1 for used points).  

```{r }
avails$y<-0 # response
# used<-use
used<-used[inkde1==1|inkde2==1,]
used$y<-1
colnames(used)[1]<-"LONG_X"    
colnames(used)[2]<-"LAT_Y"    

used<-used[,names(avails)]  # only keep necessary columns...
```

```{r cache=TRUE}


# Merge the use and availability data sets for fitting logistic regression models  
# Create weights (weight availability points using a large number)

```{r }
alldat<-rbind(used,avails)
alldat$wt<-1
alldat$wt[alldat$y==0]<-10000
unique(alldat$y)
table(alldat$y)
```

Create an offset = log(area/$n_a$) so that the intercept in the logistic regression models is comparable to that
of the point process model
```{r cache=TRUE}

g1<-kdecontour1
g2<-kdecontour2

kdecontour<-rbind(g1,g2)

kde.owin<-owin(poly=list(x=rev(kdecontour[duplicated(kdecontour)!=T,1]), y=rev(kdecontour[duplicated(kdecontour)!=T,2])))

hrarea<-area.owin(kde.owin)
alldat$off<-log(hrarea/navail)
```
Plots to look at distribution of covariates at used and available locations.

```{r fig.height=10, fig.width=10}
```{r cache=TRUE}
par(mfrow=c(2,2))
uriv<-bkde(used$waterboddist, range.x=c(0,20000), gridsize=1000)
ariv<-bkde(avails$waterboddist, range.x=c(0,20000), gridsize=1000)
plot(uriv, type="l", xlab="Distrince to nearest waterbody over .5ha", ylab="Density")
lines(ariv, lty=2)
legend("topright", lty=c(1,2), bty="n", c("Used","Available"))
uroad<-bkde(used$distsnowmob, range.x=c(0,5000), gridsize=500)
aroad<-bkde(avails$distsnowmob, range.x=c(0,5000), gridsize=500)
plot(uroad, type="l", xlab="Distrince to snowmob trail", ylab="Density")
lines(aroad, lty=2)
plot(uriv$x, uriv$y/ariv$y, type="l", xlab="Distance to lake/pond", ylab="Use/Avail")
plot(uroad$x, uroad$y/aroad$y, type="l", xlab="Distance to nearest snowmob trail", ylab="Use/Avail")




par(mfrow=c(1,1))
uriv<-bkde(used$distlinear2, range.x=c(0,20000), gridsize=1000)
ariv<-bkde(avails$distlinear2, range.x=c(0,20000), gridsize=1000)
plot(uriv, type="l", xlab="Distrince to nearest linear feature", ylab="Density")
lines(ariv, lty=2)
legend("topright", lty=c(1,2), bty="n", c("Used","Available"))



```
Look at a table of categorical values

```{r }
par(mfrow=c(1,1))
vegtab<-table(alldat$y, alldat$veg)
prop.table(vegtab,1)
plot(vegtab)
nlcdtab[1:2]

# combine similar hab values (from first analysis and remove unclassified (aka Canada))

#convert herbaceous to emergent herbaceous
alldat$veg[alldat$veg=="71"]<- "95"

#remove Canuck points
alldat<-alldat[alldat$veg!="0",]

#call all developed the same thing
alldat$veg[alldat$veg=="21"|alldat$veg=="22"|alldat$veg=="23"|alldat$veg=="24"]<- "21"

#combine hay/pasture and cultivated crops
alldat$veg[alldat$veg=="81"]<- "82"

alldat$veg<-droplevels(alldat$veg)

table(alldat$veg)

```
# Fit logistic regression models with and without weights  
Changed the reference level from "Open water" to "Mixed Forest"

```{r }
names(alldat)

alldat$veg<-as.factor(alldat$veg)
alldat$veg <- relevel(alldat$veg, ref = "43")
head(alldat)

fit1<-glm(y~waterboddist+distlinear2+as.factor(veg)+offset(off), data=alldat, family=binomial())
summary(fit1)

fit1w<-glm(y~waterboddist+distlinear2+as.factor(veg)+offset(off), weights=wt,data=alldat, family=binomial())
summary(fit1w)
```
# Fit ppp model using the same use and availability points

```{r }
# used.ppp<-ppp(used[,1], used[,2],window=as.owin(kde.owin))
# Q <- quadscheme(data=used.ppp, dummy=list(x=avails[,1], y=avails[,2]))
# df <- data.frame(lakepnddist=c(used$lakepnddist, avails$lakepnddist), veg=c(used$veg, avails$veg),
#                  distsnowmob=c(used$distsnowmob, avails$distsnowmob))
# 
# ppfit<- ppm(Q, ~ distsnowmob+lakepnddist+as.factor(veg), Poisson(), covariates=df)
# summary(ppfit)
```
Lastly, rsf fit from Lele & Keim 

```{r }

rsffit<-rsf(y~waterboddist+distlinear2+as.factor(veg)+offset(off), data=alldat, m=0)
summary(rsffit)

rsfout<-as.data.frame(summary(rsffit)$coefficients)


nlcdtab[1:2]
unique(alldat$veg)
table(alldat$veg)

# coef(rsffit)
# rsffit$std.error[1]
# cfH<-data.frame(summary(rsffit)$Std.Error)

```

# Now, compare the coefficients from the different fitted models

```{r }
coefs<-cbind(coef(fit1), coef(fit1w), c(NA,coef(rsffit)))
#removed coef(ppfit)
colnames(coefs)<-c("LR no wts", "LR wt", "rsf") 
#removed "PPM"
rownames(coefs)<-names(coef(fit1))             
outcoefs<-print(format(coefs,digits=3, scientific=T), quote=F)

filename


setwd("C:/Users/ditme004/Dropbox/Moose_Manu_Code/NE_VNP/WolfMoose_FPT_RSF/WolfRSFOut_VNP/RSFfit/")

write.csv(rsfout, file=paste(filename, ".csv", sep=""))

setwd("C:/Users/ditme004/Dropbox/Moose_Manu_Code/NE_VNP/WolfMoose_FPT_RSF/WolfRSFOut_VNP/AllCoefs/")
write.csv(outcoefs, file=paste(filename, ".csv", sep=""))

```

# Possible diagnostics using output of ppm model  
Some diagnostic plots

```{r fig.width=10, fig.height=10}
 diagnose.ppm(ppfit)
# te<-quadrat.test(ppfit)
# te
# plot(te)
```






